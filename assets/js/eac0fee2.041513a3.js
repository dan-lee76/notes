"use strict";(self.webpackChunknottes=self.webpackChunknottes||[]).push([[2509],{3905:function(e,t,n){n.d(t,{Zo:function(){return s},kt:function(){return d}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var u=r.createContext({}),p=function(e){var t=r.useContext(u),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},s=function(e){var t=p(e.components);return r.createElement(u.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,u=e.parentName,s=o(e,["components","mdxType","originalType","parentName"]),m=p(n),d=a,h=m["".concat(u,".").concat(d)]||m[d]||c[d]||i;return n?r.createElement(h,l(l({ref:t},s),{},{components:n})):r.createElement(h,l({ref:t},s))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,l=new Array(i);l[0]=m;var o={};for(var u in t)hasOwnProperty.call(t,u)&&(o[u]=t[u]);o.originalType=e,o.mdxType="string"==typeof e?e:a,l[1]=o;for(var p=2;p<i;p++)l[p]=n[p];return r.createElement.apply(null,l)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},4089:function(e,t,n){n.r(t),n.d(t,{assets:function(){return s},contentTitle:function(){return u},default:function(){return d},frontMatter:function(){return o},metadata:function(){return p},toc:function(){return c}});var r=n(7462),a=n(3366),i=(n(7294),n(3905)),l=["components"],o={},u="Introduction to Machine Learning",p={unversionedId:"Year1/AI/22.02.08 - Machine Learning_ ANN",id:"Year1/AI/22.02.08 - Machine Learning_ ANN",title:"Introduction to Machine Learning",description:"Instead of writing program by hand, give computer a lot of examples / data with the output, so computer can learn to improve",source:"@site/docs/Year1/1008-AI/22.02.08 - Machine Learning_ ANN.md",sourceDirName:"Year1/1008-AI",slug:"/Year1/AI/22.02.08 - Machine Learning_ ANN",permalink:"/Year1/AI/22.02.08 - Machine Learning_ ANN",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"year1",previous:{title:"Introduction",permalink:"/Year1/AI/22.02.01 - Introduction"},next:{title:"22.02.15 - Machine Learning (INTRO)",permalink:"/Year1/AI/22.02.15 - Machine Learning (INTRO)"}},s={},c=[{value:"Machine Learning",id:"machine-learning",level:2},{value:"Artificial Neural Networks",id:"artificial-neural-networks",level:2},{value:"Neurons",id:"neurons",level:3},{value:"First Neural Networks",id:"first-neural-networks",level:3},{value:"Training a NN",id:"training-a-nn",level:3},{value:"Current AI Developments",id:"current-ai-developments",level:2}],m={toc:c};function d(e){var t=e.components,o=(0,a.Z)(e,l);return(0,i.kt)("wrapper",(0,r.Z)({},m,o,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"introduction-to-machine-learning"},"Introduction to Machine Learning"),(0,i.kt)("h1",{id:"neural-networks"},"Neural Networks"),(0,i.kt)("p",null,"Instead of writing program by hand, give computer a lot of examples / data with the output, so computer can learn to improve"),(0,i.kt)("h2",{id:"machine-learning"},"Machine Learning"),(0,i.kt)("p",null,"Machine learning is concerned with computer programs that automatically improve their performance through experience "),(0,i.kt)("p",null,"Study of computer algorithms that can improve automatically through experiences without being explicitly programmed"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Top-down/Classic: model all different functions and wire all these 'agents' together"),(0,i.kt)("li",{parentName:"ul"},"Bottom-up / Deep learning: give the system a lot of data ")),(0,i.kt)("h2",{id:"artificial-neural-networks"},"Artificial Neural Networks"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Simulate, in the computer, neural networks in the brain"),(0,i.kt)("li",{parentName:"ul"},"McCulloh and Pits (1943): 1st neural networks",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Combine simple inputs, idea of threshold"),(0,i.kt)("li",{parentName:"ul"},"Weights design by humans"))),(0,i.kt)("li",{parentName:"ul"},"Hebb (1949): First learning rule",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Would adjust weights as it was ran"))),(0,i.kt)("li",{parentName:"ul"},"50s/60s",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Perceptrpm: great excitement"),(0,i.kt)("li",{parentName:"ul"},"Coverage to correct weights: learning $\\to$ thinking"))),(0,i.kt)("li",{parentName:"ul"},"1969: death/winter of ANN ",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Perceptron cant learn certain type of important functions (non- linear separable)"))),(0,i.kt)("li",{parentName:"ul"},"Mid 80s: discovered multi-layer networks to solve problem of non-linear separable")),(0,i.kt)("h3",{id:"neurons"},"Neurons"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},'Signals "move" between neurons'),(0,i.kt)("li",{parentName:"ul"},"Sum of inputs >= threshold, neuron ",(0,i.kt)("strong",{parentName:"li"},"fires")," (output of 1)"),(0,i.kt)("li",{parentName:"ul"},"Long-term firing patters - basing learning"),(0,i.kt)("li",{parentName:"ul"},"Theory behind first neural network"),(0,i.kt)("li",{parentName:"ul"},"McCulloch and Pitts produced the 1st neural networks in 1943")),(0,i.kt)("h3",{id:"first-neural-networks"},"First Neural Networks"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Fundamental processing unit of a brain: a neuron"),(0,i.kt)("li",{parentName:"ul"},"A processing element - (neuron)"),(0,i.kt)("li",{parentName:"ul"},"Inputs (dendrites)"),(0,i.kt)("li",{parentName:"ul"},"Output (axon)"),(0,i.kt)("li",{parentName:"ul"},"Weights (synapses)")),(0,i.kt)("p",null,"Positive weight: excitatory, otherwise inhibitory "),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"8f7d9d6504f97d72a58c200294c3014e.png",src:n(9062).Z,width:"524",height:"296"}),"\nAs long as the sum is above the threshold its correct"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"2edf4d1b6db1e258e068d9f261d7b02a.png",src:n(4117).Z,width:"899",height:"673"})),(0,i.kt)("h3",{id:"training-a-nn"},"Training a NN"),(0,i.kt)("p",null,"Weights are normally randomly assigned"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Epoch"),": Entire training set feed into the neural network. The AND function: an epoch consists of four sets of inputs(patterns) feed into the network"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Training Value, T"),": Value that we require the network to produce"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Error, Err"),": The amount the output by the network O differs from the training value T"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"X_i"),": Inputs to Neuron"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"w_i"),": Weight from input X_i, to the output "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"LR (Learning Rate)")," How quickly the network converges. It is set by the experimentation, typically 0.1. This is the adjustment amount")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"While epoch produces an error\n    Check next inputs(pattern) from epoch\n    Err = T - O\n    If Err <> 0 then\n        w_i = w_i + LR * X_i * Err\n    End If\nEnd While\n")),(0,i.kt)("p",null,"Performance Measure:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Mean squared error = ",(0,i.kt)("inlineCode",{parentName:"li"},"[(T-O)^2]/n"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"(n) number of items")))),(0,i.kt)("p",null,"Linearly Separable: Functions which can be separated. Only linearly separable functions can be represented by a single layer NN, i,e, perception"),(0,i.kt)("p",null,"If you can separate your inputs and outputs with a straight line then you have found the weights"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"15786801da80d2bbcf14b1b38be2beaf.png",src:n(1097).Z,width:"1107",height:"71"})),(0,i.kt)("h2",{id:"current-ai-developments"},"Current AI Developments"),(0,i.kt)("p",null,"AlphaCode - Writes computer programs at a competitive level. Ranked top 54% in real-world programming competitions"),(0,i.kt)("p",null,"Deep Learning - Fathers of Deep Learning, Handwriting image recognition, language processing, vision etc."),(0,i.kt)("p",null,"Learning From Experience - Deep neural networks learn by adjusting the strengths of their connections to better convey input signals through multiple layers to neurons associated with the right general concepts"))}d.isMDXComponent=!0},1097:function(e,t,n){t.Z=n.p+"assets/images/15786801da80d2bbcf14b1b38be2beaf-e3cbac9d762b2ddd9fc40c9a7459763d.png"},4117:function(e,t,n){t.Z=n.p+"assets/images/2edf4d1b6db1e258e068d9f261d7b02a-bb5c12a09e7db15a909e876b48628eda.png"},9062:function(e,t,n){t.Z=n.p+"assets/images/8f7d9d6504f97d72a58c200294c3014e-c5ce713776a96db8ead538fcc4e289a6.png"}}]);