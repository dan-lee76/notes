"use strict";(self.webpackChunknottes=self.webpackChunknottes||[]).push([[2741],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>m});var i=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,i)}return a}function n(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,i,r=function(e,t){if(null==e)return{};var a,i,r={},l=Object.keys(e);for(i=0;i<l.length;i++)a=l[i],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(i=0;i<l.length;i++)a=l[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var u=i.createContext({}),o=function(e){var t=i.useContext(u),a=t;return e&&(a="function"==typeof e?e(t):n(n({},t),e)),a},p=function(e){var t=o(e.components);return i.createElement(u.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},c=i.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,u=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),c=o(a),m=r,h=c["".concat(u,".").concat(m)]||c[m]||d[m]||l;return a?i.createElement(h,n(n({ref:t},p),{},{components:a})):i.createElement(h,n({ref:t},p))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,n=new Array(l);n[0]=c;var s={};for(var u in t)hasOwnProperty.call(t,u)&&(s[u]=t[u]);s.originalType=e,s.mdxType="string"==typeof e?e:r,n[1]=s;for(var o=2;o<l;o++)n[o]=a[o];return i.createElement.apply(null,n)}return i.createElement.apply(null,a)}c.displayName="MDXCreateElement"},4534:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>u,contentTitle:()=>n,default:()=>d,frontMatter:()=>l,metadata:()=>s,toc:()=>o});var i=a(7462),r=(a(7294),a(3905));const l={},n="Process Scheduling",s={unversionedId:"Year2/2007/5",id:"Year2/2007/5",title:"Process Scheduling",description:"14/10/22",source:"@site/docs/Year2/2007/5.md",sourceDirName:"Year2/2007",slug:"/Year2/2007/5",permalink:"/Year2/2007/5",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"year2",previous:{title:"4. Threads",permalink:"/Year2/2007/4"},next:{title:"0. Introduction to Algorithms Correctness and Efficiency",permalink:"/Year2/2009/0"}},u={},o=[{value:"Multi-level Feedback Queues",id:"multi-level-feedback-queues",level:2},{value:"Scheduling in Linux",id:"scheduling-in-linux",level:2},{value:"Completely fair scheduler",id:"completely-fair-scheduler",level:3},{value:"Real time tasks",id:"real-time-tasks",level:3},{value:"Time scheduling in Linux",id:"time-scheduling-in-linux",level:3},{value:"Equal priority",id:"equal-priority",level:4},{value:"Different Priority",id:"different-priority",level:4},{value:"Multi-processor Scheduling",id:"multi-processor-scheduling",level:2},{value:"Scheduling Queues",id:"scheduling-queues",level:3},{value:"Shared Queues",id:"shared-queues",level:3},{value:"Private Queues",id:"private-queues",level:3},{value:"Related vs. Unrelated Threads",id:"related-vs-unrelated-threads",level:2},{value:"Scheduling Related Threads",id:"scheduling-related-threads",level:2},{value:"Working together",id:"working-together",level:3},{value:"Space Scheduling",id:"space-scheduling",level:3},{value:"Gang Scheduling",id:"gang-scheduling",level:3}],p={toc:o};function d(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,i.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"process-scheduling"},"Process Scheduling"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"14/10/22")),(0,r.kt)("h2",{id:"multi-level-feedback-queues"},"Multi-level Feedback Queues"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Defining characteristics of feedback queues include:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Number of queues"),(0,r.kt)("li",{parentName:"ul"},"Scheduling algorithms used for individual queues"),(0,r.kt)("li",{parentName:"ul"},"Migration policy between queues"),(0,r.kt)("li",{parentName:"ul"},"Initial access to the queues"))),(0,r.kt)("li",{parentName:"ul"},"Feedback queues are highly configurable and offer significant flexibility")),(0,r.kt)("p",null,"From windows 7 they used multi-level feedback queues."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"An ",(0,r.kt)("strong",{parentName:"p"},"interactive system")," using a preemptive scheduler with two classes and 16 priority levels in each class."),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},'"Real time" processes/threads have a fixed priority level'),(0,r.kt)("li",{parentName:"ul"},'"Variable" processes/threads can have their priorities boosted temporarily'))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Round robing algorithm is used within the queues.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Priorities are based on the process base priority (between 0-15) and thread base priority.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"A threads priority dynamically changes during execution between its base priority and the maximum priority within its class"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Interactive I/O bound processes receive a larger boost"),(0,r.kt)("li",{parentName:"ul"},"Boosting priorities prevents priority inversion")))),(0,r.kt)("h2",{id:"scheduling-in-linux"},"Scheduling in Linux"),(0,r.kt)("h3",{id:"completely-fair-scheduler"},"Completely fair scheduler"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Process scheduling has evolved over different Linux versions. This accounts for multiple processors/cores, processor affinity, and load balancing between cores"),(0,r.kt)("li",{parentName:"ul"},"Linux distinguishes between two types of tasks for scheduling"),(0,r.kt)("li",{parentName:"ul"},"Distinguishes between two types of tasks for scheduling:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"....")))),(0,r.kt)("h3",{id:"real-time-tasks"},"Real time tasks"),(0,r.kt)("p",null,"Real time is the wrong name as you cant guarantee hard deadlines.\n......"),(0,r.kt)("h3",{id:"time-scheduling-in-linux"},"Time scheduling in Linux"),(0,r.kt)("h4",{id:"equal-priority"},"Equal priority"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"The CFS devices the CPU time between all processes/threads"),(0,r.kt)("li",{parentName:"ul"},"If all ",(0,r.kt)("em",{parentName:"li"},"N")," processes/threads have the same priority:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"They will be allocated a 'time slice' equal to 1/N times the CPU time"))),(0,r.kt)("li",{parentName:"ul"},'Length of the time slice and the "available CPU time" are based on the targeted latency.'),(0,r.kt)("li",{parentName:"ul"},"If ",(0,r.kt)("em",{parentName:"li"},"N")," is very large the context switch time will be dominant, hence a lower bound on the time slice is impose by the minimum granularity.")),(0,r.kt)("h4",{id:"different-priority"},"Different Priority"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"A weighting scheme is used to take different priorities into account"),(0,r.kt)("li",{parentName:"ul"},"If process/threads have different priorities:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Every thread ",(0,r.kt)("em",{parentName:"li"},"i")," is allocated a weight w that reflects its priority"))),(0,r.kt)("li",{parentName:"ul"},"The tasks with the lowest proportional amount of used cpu time are selected first")),(0,r.kt)("h2",{id:"multi-processor-scheduling"},"Multi-processor Scheduling"),(0,r.kt)("h3",{id:"scheduling-queues"},"Scheduling Queues"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Single processor")," machine: ",(0,r.kt)("strong",{parentName:"li"},"which process(thread)")," to run next"),(0,r.kt)("li",{parentName:"ul"},"Scheduling decisions on a multi-processors/core machine include")),(0,r.kt)("h3",{id:"shared-queues"},"Shared Queues"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"A single or multi-level queues shared between all CPUs"),(0,r.kt)("li",{parentName:"ul"},"Advantage:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Automatic load balancing"))),(0,r.kt)("li",{parentName:"ul"},"Disadvantage:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Contention for the queues"),(0,r.kt)("li",{parentName:"ul"},"Does not account for processor affinity (cache becomes invalid when moving to a different CPU)"))),(0,r.kt)("li",{parentName:"ul"},"Windows will allocate the highest priority threads to the individual CPUs/cores")),(0,r.kt)("h3",{id:"private-queues"},"Private Queues"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Each CPU has a private (set) of queues"),(0,r.kt)("li",{parentName:"ul"},"Advantages:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"CPU affinity")," is automatically satisfied"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Contention")," for shared queues is minimised"))),(0,r.kt)("li",{parentName:"ul"},"Disadvantages:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Less load balancing"),(0,r.kt)("li",{parentName:"ul"},"Push and pull migration between CPU is required")))),(0,r.kt)("h2",{id:"related-vs-unrelated-threads"},"Related vs. Unrelated Threads"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Related"),": multiple threads that communicate with one another and ideally run together (search algorithm)"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Unrelated"),": processes threads that are independent, possibly started by different users running different programs")),(0,r.kt)("h2",{id:"scheduling-related-threads"},"Scheduling Related Threads"),(0,r.kt)("h3",{id:"working-together"},"Working together"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Threads belong to the same process and are cooperating (exchange messages or share information)"),(0,r.kt)("li",{parentName:"ul"},"....."),(0,r.kt)("li",{parentName:"ul"},"The aim is to get threads running, as much as possible, at the same time across multiple CPUs")),(0,r.kt)("h3",{id:"space-scheduling"},"Space Scheduling"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Approach:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("em",{parentName:"li"},"N")," threads are allocated to ",(0,r.kt)("em",{parentName:"li"},"N")," dedicated CPUs"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("em",{parentName:"li"},"N")," threads are kept waiting until ",(0,r.kt)("em",{parentName:"li"},"N")," CPUs are available "),(0,r.kt)("li",{parentName:"ul"},"Non-preemptive"))),(0,r.kt)("li",{parentName:"ul"},"Number of ",(0,r.kt)("em",{parentName:"li"},"N")," can be dynamically adjusted to match processor capacity")),(0,r.kt)("h3",{id:"gang-scheduling"},"Gang Scheduling"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Time slices are synchronised and the scheduler groups thread together to run simultaneously "),(0,r.kt)("li",{parentName:"ul"},"A preemptive algorithm "),(0,r.kt)("li",{parentName:"ul"},"Blocking threads result in idle CPUs....")))}d.isMDXComponent=!0}}]);