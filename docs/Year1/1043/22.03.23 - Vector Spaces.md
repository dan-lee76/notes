# Definition of Vector Space
## Vector Space
- $E$ to be a non-null set and $K$ to be a scalar set
- Vectors: elements of the set $E$
- $+$ - Internal composition law, $E\times E \to E$
- $.$ - External composition law, $K\times E\to E$
- ($E,+,.$) is said vector space of the vector set $E$ over the scalar field ($K,+,$) if and olf if the ten vector space axioms are verified

### Axioms
- $E$ is closed with respect to the internal composition law: $∀u, v ∈ E : u + v ∈ E$
- $E$ is closed with respect to the external composition law: $∀u ∈ E and ∀λ ∈ K : λu ∈ E$
- Commutativity for the internal composition law: $∀u, v ∈ E : u + v = v + u$
- Associativity for the internal composition law: $∀u, v, w ∈ E × E : u + (v + w) = (u + v) + w$
- Neutral element for the internal composition law: $∀u ∈ E : ∃!o ∈ E|u + o = u$
- Opposite element for the internal composition law: $∀u ∈ E : ∃!−u ∈ E|u + −u = o$
- Associativity for the external composition law: $∀u ∈ E$ and $∀λ, μ ∈ K : λ(μu) = (λμ) u = λμu$
- Distributivity 1: $∀u, v ∈ E$ and $∀λ ∈ K : λ (u + v) = λu + λv$
- Distributivity 2: $∀u ∈ E and ∀λ, μ ∈ K : (λ + μ)u = λu + μu$ 
- Neutral elements for the external composition law: $∀u ∈ E : ∃!1 ∈ K |1u = u$

## Vector Subspace
($E,+,.$) be a vector space, $U \subset E$ and $U \ne ∅$
The triple ($E,+,.$) is a vector subspace of ($E,+,.$) if ($U,+,.$) is a vector space over the same field $K$ with respect to both the composition laws

Proposition shows that we do not need to prove all 10 axioms, just need to prove closure of the two composition laws.

## Null vector in Vector Spaces
($E,+,.$) be a vector space over a field $K$. Every vector subspace ($U,+,.$) of ($E,+,.$) contains the null vector.
For every vector space ($E,+,.$), at least two vector subspace exist

# Intersection and Sum Spaces
## Intersection Spaces
If ($U,+,.$) and ($V,+,.$) are two vector subspace of ($E,+,.$), then ($U\cap V,+,.$) is a vector subspace of ($E,+,.$)

## Sum Space
($U,+,.$) and ($V,+,.$) be a vector space of ($E,+,.$). Sum subset is a set $S=U+V$ defined as
$$S=U+V=\{ w\in E |\exists u \in U, v \in V|w=u+v \}$$

## Direct Sum
($U,+,.$) and ($V,+,.$) be two vector subspaces of ($E,+,.$). If $U\cap V = \{ o\}$ the subset sum $S=U+V$ is indicated as $S=U⊕V$ and named subset direct sum

# Linear dependence in $n$ dimensions
## Basic Definition
- [Linear combination](../1043%20-%20Maths%202/22.02.09%20-%20Matrices.md#linear-combination) of the $n$ vectors by means of $n$ scalars is the vector $\lambda_1v_1+\lambda_2v_2+...+\lambda_nv_n$
- Said to be [linear dependent](../1043%20-%20Maths%202/22.02.09%20-%20Matrices.md#linear-dependence) if the null vector o can be expressed as linear combination by means of the scalars $\lambda_1,\lambda_2,...,\lambda_n\ne 0,0,...,0$
- Vectors are [linearly independent](../1043%20-%20Maths%202/22.02.09%20-%20Matrices.md#linear-independence) if the null vector $o$ can be expressed as linear combination only by means of the scalars $0,0,...,0$
- Are linearly dependent if and only if at least one of them can be expressed as linear combination of the others
- Would then check them as you would do in matrices

# Linear Span
Set containing the totality of all the possibly linear combinations of the vectors, by means of $n$ scalars.
$L (v_1 , v_2 , . . . , v_n ) = \{ λ_1 v_1 + λ_2 v_2 + . . . + λ_n n |λ_1 , λ_2 , . . . , λ_n ∈ K \}$
## Properties
1. Span $L(v_1,v_2,...,v_n)$ with the composition laws in a vector subspace of ($E,+,.$)
2. $s\in \N$ with $s<n$. If $s$ vectors are linearly independent while each of the remaing $n-s$ vectors is linear combination of the linearly independent $s$ vectors, then  $L (v_1 , v_2 , . . . , v_n ) = L (v_1 , v_2 , . . . , v_s )$
3.  $L (v_1 , v_2 , . . . , v_n ) =  L (v_{(σ)1} , v_{(σ)2} , . . . , v_{(σ)no })$