# Basis of a Vector Space
## Basis
Vector space is said to be *finite-dimensional* if $\exists$ a finite number of vectors such that the vector space $(L,+,.)=(E,+,.)$ where the span $L$ is $L(v_1..)$.

A *basis* $B=\{v_1...\}$ of $(E,+,.)$ is a set of vectors $\in E$ that verify the following properties:
- They are [linearly independent](../1043%20-%20Maths%202/22.02.09%20-%20Matrices.md#linear-independence)
- They span $E$, i.e. $E = L(v_1..)$
## Null Vector and Linear Dependence
If one of the vectors is equal to the null vector, then these vectors are [linear dependent](../1043%20-%20Maths%202/22.02.09%20-%20Matrices.md#linear-dependence)
## Steinitz Lemma
 $(E,+,.)$ = Finite-dimensional vector space
 $L(v_1..)=E$ = E its span
 Let $w_1...$ be $s$ linearly independent vectors $\in E$
 Follows that $s\le n$, the number of a set of linearly independent vectors cannot be higher than the number of vectors spanning the vector space.
 ### Corollary of the Steinitz Lemma
 ^continuation
 $B=\{w_1...\}$ be its basis, it follows that $s\le n$.
 The vectors composing the basis are linearly independent. For the Steinitzs Lemma, it follows immediately that $s\le n$
# Dimension of a Basis
## Order of a Basis
Number of vectors composing a basis is said *order of a basis*
All the bases of a vector spaces have the same order
## Dimension of a Vector Space
The order of a basis is said dimension is indicated with dim $(E,+,.)$ or dim($E$).
The *dimension* dim $(E,+,.)=n$ of a vector space is:
- the maximum number of linearly independent  vectors of E
- the minimum number of vectors spanning E
## Linear independence and dimension
The vectors span the vectors if and only if they are linearly independent
# Grassmann Formula
## Reduction and Extension of a basis
**Basis Reduction Theorem** - If some vectors are removed a basis of $(E,+,.)$ is obtained
**Basis Extension Theorem** - Let $w_1..$ be $s$ linearly independent vectors of the vector space. If $w_1..$ are not already a basis, they can be extended to a basis (by adding other linearly independent vectors)

## Unique Representation
If the $n$ vectors are linearly dependent while $n-1$ is linearly independent, there is a unique way to express one vectors as linear combination of others
(How you would represent other lines with one another, identify them with lambdas)

## Grassmanns Formula
Let $(U,+,.)$ and $(V,+,.)$ be vector subspace of $(E,+,.)$. Then, 
$$dim(U+V)+dim(U\cap V) = dim(U) + dim(V)$$