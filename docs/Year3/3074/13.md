# Large Language Models
### Data used to train LLMs
- LLMs are trained in an unsupervised manner on open source, licensed and borrowed data
- Responses are refined using Q/A pairs
- Reinforcement learning with human feedback is used to reward LLMs to give appropriate responses

### LLMs can (seem to) be creative
- Context-based learning + randomness allow the LLMs to generate surprising outputs
- Can use LLMs to:
	- Identify weakly similar concepts from different disciplines and help understand different disciplines
	- Generate narratives etc

### Challenges in LLMs
- LLMs may seem to "lie" and "hallucinate"
- This is some function of data, learning, search and probability
- Remember that the output of a LLM is determined by both what the system has been trained on and what information you give it
- Prompt engineering means tailoring your questions and input so you can get the most out of an LLM

### Prompting Techniques
- Prompting techniques are about formatting your input to provide a context that the LLM ca use more effectively, restricting the probability distribution of the words it chooses to sample next

### Training phases of LLM
....