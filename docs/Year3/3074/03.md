# Modelling, representing, & generating language

### Outline and objectives
- Modelling and generation are big topics

Language **modelling** - Building a probabilistic model of language. 
Language **generation** - Using templates and probabilistic models of language to create natural-sounding testing
## Language Modelling
### Probabilistic Language Models
- Core prob
- ......

We only care about the probabilities of individual words

### Maximum Likelihood Estimation and its problems
... is the Maximum Likelihood Estimate (MLE)


### Smoothing
- What if we apply our language model on a new sentence
	- One novel bigram would pull the probability to 0


### Conclusion
- Smallest unit of thought is the n-gram
	- Unigrams let us work with single words
	- Bigrams let us work with pairs of consecutive words
	- Trigrams let us work with triples of consecutive words
- Language models let us compare the likelihood of documents

## Language Generation
### What is NLG
- NLG is the subfield of ai and computational linguistics that focuses on computer sytems that can **produce understandable texts**
- ...

### Multiple schools of NLG
- Gap-filling systems - Simplest, no novelty
- Rule-based systems - Expanded gap-filling system
- Grammatical function - Complex template system, low novelty, medium error rate
- Dynamic generation - Abstract representation, fully dynamic, high novelty, high error rate

NLP = Natural Language Understanding + Natural Language Generation