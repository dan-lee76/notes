# 25. Revision

## Computer Design
### Registers
- **Data Registers** - Any sort of data for special functions. 
- **Program Counter-** Holds the next instruction.
- **Program status word**  - admin, stores the mode bit. Which mode the CPU is in, kernel mode or user mode.
- **User Mode** - Direct access to a subset of instructions the CPU can carry out
- **Kernel mode** - Access to the full set of instructions. Including privileged memory locations. 
- Normally compiler decides which mode to use

### Memory Management Unit
*Location of an address*
Doesn't know where in memory an executable will run. Variables require memory, they need to have a memory space
- **Logic Address Space** -  Used by the processor and the compiler (starts at 0). What you use when you write code. Every process has one [0,MAX^64] 
- **Physical Address Space** - Seen by the hardware/OS [0,MAX] (Determined by the amount of physical memory)
Also responsible for address translation `physical = locgical + x`

### Moors Law
> **Moore's law** - The number of transistors on an integrated circuit doubles roughly every two years. 

Closely linked but necessarily related to performance. 
Still continuing but the power wall slows performance improvements of single core
Can extract parallelism automatically, can implement it at the lowest level

### Multi-core, hyper-threaded processors
Evolution in hardware has implications on OS design
The process scheduling needs to account for load balancing and CPU affinity. Need to decide **when** and **where** it is going to run

### Micro Kernels
All non-essential functionality is extracted from the kernel. These are easier to extend, more portable and more reliable.
Frequent system calls cause mode switches/overhead

**Monolithic Systems** - All procedures into one single executable running in kernel mode. However, they are difficult to maintain. Current versions of Windows, and Linux are implemented as this.

## Introduction to processes
Running instance of a program. This has 'control structures' - they store all the necessary information related to the management of the process

### Context Switching
Process control box contains:
- **Process identification** (PID, UID, Parent PID)
- **Process control information** (process state, scheduling information)
- **Process state information** (user registers, program counter, stack pointer, program status word, memory management information, files)
The **process control block** is **necessary** for **context switching** in **multi-programmed systems**
Process control blocks are kernel data structures, which are stored in the **process table** and are accessible in the **kernel mode** only (system calls), otherwise this would compromise their integrity.

#### Multi-Programming
Achieved by alternating processes and context switching
- Single processor systems results in concurrent execution
- True parallelism requires multiple processors

Slow time slices - good response times, low utilisation
Long time slices - poor response times, better utilisation

#### Process
Memory image contains: the program (shared) code, data segment (stack/heap)
Every process has own logical address space
Some OS address space layout are randomised 

### Process implementation
Information about the status of "resources" is maintained in tables. These are in kernel space and cross referenced
- **Process tables** - process control blocks
- **Memory tables** - memory allocation, protection, virtual memory 
- **I/O tables** - Availability, status, transfer information
- **File tables** - Location, status

### States and Transitions
![](../_resources/20221007111037.png)
- **New** process has just been created and is waiting to be admitted
- **Ready** process is waiting for the CPU to become available
- **Running** process 'owns' the CPU
- **Blocked** process cannot continue (waiting for IO)
- **Terminated** process is no longer executable
- **Suspended** process is swapped out

### System Calls
- True system calls are "wrapped" in the OS libraries following a well defined interface
- These are necessary to notify the OS that the process has terminated
- `fork()` - creates an exact copy of the current process

## Process Scheduling
- New -> ready: when to admit processes to the system
- Ready -> running: decide which process to run next
- Running -> ready: when to interrupt process
- **Scheduler** - decides which process to run next
- **Type of operating system** - determines which algorithms are appropriate

### Time Horizon
- **Long term** - admits new processes and controls the degree of multi programming. Good mix of CPU and IO bound processes. Usually absent in popular modern 
- **Medium term** - controls swapping. Looks to see how busy the system currently is. 
- **Short term** - which process to run next. Manages the ready queue, runs frequently (must be fast). Called following clock interrupts or blocking system calls.

### Process Schedulers
- **Non-Preemptive** - Processes are interrupted voluntarily
- **Preemptive** - Processes are interrupted forcefully or voluntarily. Requires context switches. Prevents process from monopolising the CPU. Most popular OS are preemptive

### Performance Assessment
- User Oriented Criteria
	- **Response time**: time between creating the job and its first execution
	- **Turnaround time**: time between creating the job and finishing it
	- **Predictability**: variance in processing times
- System oriented criteria:
	- Throughput: number of jobs processed per hour
	- Fairness: Equally distributed processing.

### Scheduling Algorithms
| Algorithm                                  | Concept                                                                                                                                                                | Advantage                                                                              | Disadvantage                                                                                                      |
| ------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |
| First Come First Served/First in First out | Non-preemptive algorithm that operates as a strict queuing mechanism.                                                                                                  | Positional fairness an easy to implement                                               | Favours long processes over short ones. Could compromise resource utilisation.                                    |
| Shortest Job First                         | A non-preemptive algorithm that starts processes in order of ascending processing time                                                                                 | Always result in the optimal turnaround time                                           | Starvation might occur. Fairness and predictability are compromised. Processing times have to be known beforehand |
| Round Robin                                | A preemptive version of FCFS. Processes run in the order they were added but they only get a max amount of time at once. Forces context switches at periodic intervals | Improved response time. Effective for general purpose interactive/time sharing systems | Increased context switching and overhead. Favours CPU bound processes over IO. Can reduce to FCFS.                |
| Priority Queue                             | A preemptive algorithm that schedules processes by priority. Round robin is used within the same priority levels. Saved by the process control block                   | Can priorities IO bound jobs                                                           | Low priority may suffer from starvation                                                                           |


## Threads
- **Resources** - All related resources are grouped together
- **Execution trace** - entity that gets executed
- A process can share its resources between multiple execution traces/threads

Every thread has its own execution context & thread control block, however they all have access to the processes shared resources.
Execution of a process has states (new, running, blocked, read, terminated)

| Shared Resources (Processes) | Private Resources (Threads) |
| ---------------------------- | --------------------------- |
| Address space                | Program Counter             |
| Global variables             | Registers                   |
| Open files                   | Stack                       |
| Child processes              | State                       |
| Pending alarms               | Local vars                  |
| Signals and signal handling  |                             |
| Accounting information       |                             |

Threads incur less overhead to create/terminate/switch
Hyper threaded cores have hardware support for multi-threading

- **Inter-thread communication**: Easier/faster than **interprocess** communication (memory is shared)
- **No protection boundaries**: Required in the address space (threads are cooperating, belong to the same user, and have a common goal)
- **Synchronisation**: Has to be considered carefully

### Reason to use threads
- Processes will often contain multiple blocking tasks (IO operations & memory access page faults)
- Some activities should be carried out in parallel/concurrently such as webservers, msoffice etc

### User Threads
*Many-to-One*
- Thread management is executed in user space with the help of a user library
- Process maintains a thread table, managed by the runtime system without the kernels knowledge.
- Kernel can see 1 process, but user space can see multiple
- Advantages - Full control over the thread scheduler, OS independent and in user space
- Disadvantages - Blocking system calls suspend the entire process (can be cause by page faults), no true parallelism, clock interrupts don't exist.

### Kernel Threads
*One-to-One*
- Kernel manages threads, user access them through system calls. Thread table is maintained by the kernel. If a thread blocks, the kernel chooses thread
- Advantages - True parallelism, no run-time needed
- Frequent mode switches take place (performance)

### Performance
- **Null fork** - the overhead is creating, scheduling, running and terminating a null process/thread
- **Signal wait** - overhead is synchronising threads

### Hybrid Implementations
- User threads are multiplexed onto kernel threads
- Kernel sees and schedules the kernel threads
- User applications sees user threads and creates/schedules these

### Thread Management
- Libraries are either user space or based on system calls

## Process Scheduling
Characteristics of feedback queues include; number of queues, scheduling algorithms, migration policy and initial access. These queues are highly configurable.
- **Real time** - processes/threads have a fixed priority level
- **Variable** - processes/threads can have their priorities boosted temporarily 
Priorities are based on the process base priority(0-15) and thread base priority (+-2 relative to the process priority)
Threads priority dynamically changes during execution. (between base and max priority)

### Completely fair scheduler
Linux has Real time tasks, FIFO and Round Robin, and Time sharing tasks using a preemptive approach.
Real time FIFO takes highest priority, and preemption if a higher priority shows up
Real time round robin tasks are preemptable by clock interrupts and have a time slice associated with them. 

#### Equal priority
CFS divides the CPU time between all processes/threads. If all *N* have same priority, they will be allocated a time slice. The length of the time slice are based on the targeted latency. If *N* is very large, the context switch time will be dominant, and a lower bound on the time slice.

#### Different priority
A weighing scheme is used to take different priorities into account. If different priority,  then every *i* is allocated a weight *w* that reflects its priority. The tasks with the lowest proportional amount of used CPU time are selected first

### Multi-processor scheduling
- **Single Processor** machine - Which process(thread) to run next
- **Shared Queues** - Single or multi-level shared between all CPUs. + Automatic load balancing. - Contention for the queues (locking if needed), does not account for processor affinity
- **Private Queues** - Each CPU has a private set of queues. + CPU affinity is automatically satisfied, contention for shared queues minimised. - Less load balancing, push and pull migration between CPUs is required
- **Related Threads** - Multiple threads that communicate with one another and ideally run together (search algorithm)
- **Unrelated Threads** - Processes threads that are independent, possibly started by different users running different programs
- Working together - Aim is to get threads running, as much as possible, at same time across multiple CPUs
- **Space Scheduling** - Number *N* can be dynamically adjusted to match processor capacity
- **Gang Scheduling** - Time slices are synchronised and the scheduler groups threads together to run simultaneously. Preemptive algorithm, blocking threads result in idle CPUs

------------
*This is where Dan the retard compresses his notes instead of 'shortening' them*

## Concurrency
- Threads/processes execute concurrently and share resources. These can be interrupted at any point. Process state is saved in the process control block.
- Outcomes of programs are unpredictable. Sharing data leads to inconsistencies. 

### Race Conditions
- Occurs when multiple threads/processes access shared data and same time.
- Mechanisms such as semaphores and mutexes can prevent this.
- OS must make sure that interactions within the OS do not result in race conditions
	- Must provide locking mechanisms to implement/support mutual exclusions and prevent starvation/deadlocks

**Critical Section** - Set of instructions in which shared resources between processes/threads are changed. Only one can access it at once, so need to ensure it gets locked whilst in use. Solutions must allow process to enter it as some point, and ensure there is fairness within the program.

**Mutual Exclusion** - Must be enforced for critical sections. Processes need to get permissions before entering critical section. Solutions can be software based (Peterson solution), hardware, mutexes/semaphores, monitors. Deadlocks also need to be prevented

### Deadlocks 
> Set of p/t is deadlocked if each p/t in the set is waiting for an event that only the other p/t in the set can access

Mutexes can cause deadlocks. **All** four conditions must hold for deadlocks to occur
1. **Mutual exclusion**: a resource can be assigned to at most one process at a time
2. **Hold and wait condition**: a resource can be held whilst requesting new resources
3. **No preemption**: resources cannot be forcefully taken away from a process
4. **Circular wait**: there is a circular chain of two or more processes, waiting for a resource held by the other processes.

### Peterson's Solution
- **Software Solution** - Worked well on older machines. Two shared variables are used `turn` (next in critical section) and `boolean flag[2]`(process is read to enter the critical section.[Code](07.md#Peterson's_Solution)
- **Mutual Exclusion Requirement** - Satisfies all critical section requirements. Only want one process on the thread accessing the critical section at once
- **Progress Requirement** - Any process must be able to enter its critical section at some point in time.
- **Fairness/bound waiting** - Fairly distributed waiting times/processes cannot be made to wait indefinitely

**Disabling Interrupts** - Disable whilst executing a critical section and prevent interrupts. May be appropriate on single CPU machine. Insufficient on modern machines

**Atomic Instructions** - Implement `test_and_set()` and `swap_and_compare()` instructions as a set of atomic (= uninterruptible) instructions. Reading and setting is done as one complete instruction. If called simultaneously, they will be executed sequentially.

**Mutual Exclusion** - `test_and_set()` and `swap_and_compare()` are hardware instructions and not directly accessible to the user. Other disadvantages include busy waiting, and deadlocks